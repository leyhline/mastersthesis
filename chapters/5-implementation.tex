\chapter{Implementation}\label{chap:implementation}

The actual implementation uses the Haskell programming language and related tools. Adjustments in all four module groups as defined in chapter~\ref{chap:program-structure} are necessary. Furthermore, the data types in the fundamental \texttt{Syntax} module must be extended with the additional expression and types introduced in section~\ref{sec:cc-expressions}.

\begin{lstlisting}[caption=Syntax.hs]
data Exp = ...
  | Cast Exp Type Type  -- M : A => B

data Type = ...
  | TBot  -- bottom type
  | TDyn  -- dynamic type *
\end{lstlisting}

\section{Parsing}

As usual, there is a tokenization step before the actual parsing, turning a string into tokens. For this purpose, we use the tool \emph{Alex: A lexical analyser generator for Haskell}\footnote{\url{https://www.haskell.org/alex/}}, maintained by Simon Marlow, as it nicely integrates with Haskell. We add tokens for the bottom type and the the double arrow used in cast expressions. In our implementation, we use \texttt{*} as identifier for the dynamic type. There already exists a corresponding token since it was used for multiplication in the base language.

\begin{lstlisting}[caption=Parsing/Tokens.x]
data Token = ...
  | TBot
  | DoubleArrow

tokens :-
  ...
  Bot    { tok $ const TBot }
  "_|_"  { tok $ const TBot }
  "=>"   { tok $ const DoubleArrow }
\end{lstlisting}

For parsing, we use \emph{Happy: The Parser Generator for Haskell}\footnote{\url{https://www.haskell.org/happy/}}, also maintained by Simon Marlow. Parsing is slightly more complicated since we need to add the dynamic type $\star$, bottom type and the cast expression $M : A \Rightarrow B$.

\begin{lstlisting}[caption=Parsing/Grammar.y]
%token
  ...
  Bot   { T _ T.TBot }
  '=>'  { T _ T.DoubleArrow }

Exp = ...
  | Exp ':' Typ '=>' Typ  { Cast $1 $3 $5 }

ATyp = ...
  | '*'  { TDyn }
  | Bot  { TBot }
\end{lstlisting}

\section{Typechecker}

Since terms involving the newly introduced dynamic type are handled at runtime there is no need for extensive changes to the typechecker. Nevertheless, we need to integrate the new syntax. Otherwise, typechecking would fail, not because of type errors but out of ignorance.

\subsection{Type Synthesis}

In general, type synthesis $\Gamma \vdash M \Rightarrow A;\Delta$ takes environment $\Gamma$ and expression $M$ to synthesize its type $A$ and the environment after $\Delta$. We adjust the corresponding function for the following expressions: (1) application, (2) pair construction and for built-in functions (3) \texttt{fst} and (4) \texttt{snd} (both eliminating pairs, yielding the first or second element). In code, it is complemented by a monad transformer, as seen in its annotation, though this is not relevant here.

\begin{lstlisting}[caption=\texttt{tySynth} function type annotation]
tySynth :: TEnv -> Exp -> TCM (Type, TEnv)

type TCM a =
  WriterT [Constraint] (ExceptT String (State Caches)) a

data Caches = Caches{subCache::Cache, eqvCache::Cache}
type Cache = [(Type, Type)]

data Constraint = Type :<: Type
\end{lstlisting}

For application $M N$, after synthesizing $\Gamma \vdash M \Rightarrow A;\Delta$ and if $A = \star$, we assert that expression $N$ also has dynamic type $\star$.

\begin{lstlisting}[caption=TCTyping.hs]
tySynth te (App e1 e2) = do
  (tf, te1) <- tySynth te e1
  tfu <- unfold te1 tf
  case tfu of
    -- ...
    TDyn -> do
      te2 <- tyCheck te1 e2 TDyn
      return (TDyn, te2)
\end{lstlisting}

An expression involving pairs is ``\lstinline[language=ldgv]!let <x, y> = M in N!'', where $M$ has a pair type. First, the components of $M$ are bound to $x$ and $y$, finally evaluating $N$. For typecheckig, we first synthesize type $A$ from $M$. Finally, we synthesize $\Delta_A, x:\star, y:\star \vdash N \Rightarrow B$ for the whole expression's type.

\begin{lstlisting}[caption=TCTyping.hs]
tySynth te (LetPair x y e1 e2) = do
  (tp, te1) <- tySynth te e1
  tpu <- unfold te1 tp
  case tpu of
    TPair {} -> -- ...
    TDyn -> tySynth
      ((y, (Many, TDyn)) : (x, (Many, TDyn)) : te1)
      e2
\end{lstlisting}

The built-in functions \texttt{fst} and \texttt{snd} simply return the dynamic type $\star$ upon type synthesis since a pair type $\Sigma(x:\star)\star$ implies that both components are of type $\star$, too.

\subsection{Subtyping}

Subtyping regarding the dynamic type happens in the context of \case, used for eliminating label types. For term $\case (x:\star \Rightarrow A) \{ \overline{\ell : N_\ell} \}$ we check if type $A$ is a subtype of $N_\ell$. Both are sets of label, hence $A \leq N_\ell$ if $A \subseteq N_\ell$.

\begin{lstlisting}[caption=TCSubtyping.hs]
unfold :: TEnv -> Type -> TCM Type
unfold tenv (TCase val@(Var x) cases) = do
  tyx <- varlookupUnfolding x tenv
  let f :: (String, Type) -> TCM Type
      f (lab, labtyp) = unfold
        (("*unfold*", TEqn val (Lit $ LLab lab) tyx) : tenv)
        labtyp
  case tyx of
    TLab {} -> -- ...
    TDyn -> mapM f cases
  where f ::
\end{lstlisting}

\section{Interpreter}

In basic LDGV, types are not relevant in context of evaluation. The interpreter works on the assumption that prior typechecking did succeed. In our extension, cast expressions are always handled at runtime, even if both types in a cast $V : A^\circ \Rightarrow B^\circ$ are not dynamic ($A \neq \star, B \neq \star$).
For correct handling of the dynamic type and type reduction of cast expressions we introduce new data types and extend the existing data type for values. Finally, we implement the rules of section~\ref{sec:ccldlc-inference-rules}.

\todo{What about Singletons?}

\subsection{Type passing}

Since types reduction requires \emph{head normal form} we introduce an explicit data type \texttt{NFType}. Label type $L$ is implemented as a set of strings. Similarities between function type $(\rho, \Pi(x:A)B)$ and pair type $(\rho, \Sigma(x:A)B)$ are  depicted using the \texttt{FuncType} data type.

\begin{lstlisting}[caption=ProcessEnvironment.hs]
data NFType
  = NFBot
  | NFDyn
  | NFUnit
  | NFLabel LabelType
  | NFFunc FuncType
  | NFPair FuncType
  | NFInt
  | NFDouble
  | NFGType GType

type Label = String
type LabelType = Set Label
data FuncType = FuncType PEnv String Type Type
\end{lstlisting}

The constructor \texttt{NFGType} is a special case. It takes an argument of type \texttt{GType}---the data type implementing \emph{ground types}---which we define next. This type dependency depicts that every ground type is also in head normal form while making comparison operations between \texttt{NFType} and \texttt{GType} possible. At the same time, defining ground types as a separate data type allows for more precise functions.

\begin{lstlisting}[caption=ProcessEnvironment.hs,label=lst:gtype]
data GType
  = GUnit
  | GLabel LabelType
  | GFunc
  | GPair

equalsType :: NFType -> GType -> Bool
equalsType NFUnit GUnit = True
equalsType (NFLabel ls1) (GLabel ls2) = ls1 == ls2
equalsType (NFFunc (FuncType _ _ TDyn TDyn)) GFunc = True
equalsType (NFPair (FuncType _ _ TDyn TDyn)) GPair = True
equalsType (NFGType gt1) gt2 = gt1 == gt2
equalsType _ _ = False
\end{lstlisting}

Subtyping checks are implemented with typeclass \texttt{Subtypeable} with instances for ground types \texttt{GType}---mostly with trivial definitions---and partially for HNF types \texttt{NFType}. The latter is solely necessary for implementing the \emph{Cast-Dyn-Dyn} rule.

\begin{lstlisting}[caption=ProcessEnvironment.hs]
class Subtypeable t where
  isSubtypeOf :: t -> t -> Bool

instance Subtypeable GType where
  isSubtypeOf GUnit GUnit = True
  isSubtypeOf (GLabel ls1) (GLabel ls2) =
    ls1 `isSubsetOf` ls2
  isSubtypeOf GFunc GFunc = True
  isSubtypeOf GPair GPair = True
  isSubtypeOf _ _ = False

instance Subtypeable NFType where
  isSubtypeOf NFBot _ = True
  isSubtypeOf NFDyn NFDyn = True
  -- ...
  isSubtypeOf _ _ = False
\end{lstlisting}

We also extend the value type for $V : G \Rightarrow \star$ and function casts:

\begin{lstlisting}[caption=ProcessEnvironment.hs]
data Value = -- ...
  | VDynCast Value GType
  | VFuncCast Value FuncType FuncType
\end{lstlisting}


\subsection{Type inference}

The goal of type inference at runtime is to either reduce casts in a way that evaluation halts at a value, or to abort evaluation with \blame which will throw an exception. Here, we describe the implementation of the rules we stated in figure~\ref{fig:ccldlc-extensions-values}.

We extended the language with cast expression $M : A \Rightarrow B$. A cast reduction needs form $V : A^\circ \Rightarrow B^\circ$. Hence, we use rule \textsc{Cast-Reduce} to evaluate expression $M$ to value $V$ and types $A$ and $B$ to HNF types $A^\circ$ and $B^\circ$. For that purpose, we extend the existing \texttt{eval} function.

\begin{lstlisting}[caption=Interpreter.hs,label=lst:cast-reduce]
eval :: Exp -> InterpretM Value
eval cast@(Cast e t1 t2) = do
  v <- interpret' e
  nft1 <- evalType t1
  nft2 <- evalType t2
  maybe (blame cast) return (reduceCast v nft1 nft2)
\end{lstlisting}

Here, we also introduce the \texttt{evalType} function since types and type evaluation were not relevant before (see \emph{type erasure}). Mostly, the evaluation to HNF types is trivial. For function and pair types, the environment is made part of the type. Most involved is evaluation of the $\case x~\{\ell_i : A_i\}$ type since no such type is in HNF. We match label $x \downarrow \ell_j$ on the type mapping, finally evaluating $A_j \downarrow A^\circ$.

\begin{lstlisting}[caption=Interpreter.hs]
evalType :: Type -> InterpretM NFType
evalType = \case
  TUnit -> return NFUnit
  TInt -> return NFInt
  TDouble -> return NFDouble
  TBot -> return NFBot
  TDyn -> return NFDyn
  TLab ls -> return $ NFLabel ls
  TFun _ s t1 t2 -> do
    penv <- ask
    return $ NFFunc $ FuncType penv s t1 t2
  TPair _ s t1 t2 -> do
    penv <- ask
    return $ NFPair $ FuncType penv s t1 t2
  TCase exp labels -> interpret' exp >>= \(VLabel l) ->
    let entry = find (\(l', _) -> l == l') labels
    in maybe (return NFBot) (evalType . snd) entry
\end{lstlisting}

Cast reduction $V : A^\circ \Rightarrow B^\circ \Downarrow V'$ is implemented in the \texttt{reduceCast} function. Its type signature requires a value and two types in HNF, too. However, upon failure it will not return \blame directly but encapsulates its result into type \texttt{Maybe}. The calling function needs to call \blame upon an empty result.

The basic \textsc{Cast-Is-Value} rule returns $V : A^\circ \Rightarrow B^\circ$ as it is if it already forms a value. This occurs for $A^\circ = G, B^\circ = \star$ (\texttt{VDynCast})\footnote{Reminder: Comparison over HNF types \texttt{NFType} and ground types \texttt{GType} is possible using the \texttt{equalsType} function from listing~\ref{lst:gtype}.} or for function casts, i.e. $A^\circ=(\rho, \Pi(x:A)A'), B^\circ=(\rho, \Pi(x:B)B')$ (\texttt{VFuncCast}).

\begin{lstlisting}[caption=Interpreter.hs]
reduceCast :: Value -> NFType -> NFType -> Maybe Value
reduceCast v t1 t2 = castIsValue v t1 t2
                 <|> reduceCast' v t1' t2'
  where t1' = packGType t1
        t2' = packGType t2

castIsValue :: Value -> NFType -> NFType -> Maybe Value
castIsValue v t NFDyn = do
  gt <- matchType t
  if t `equalsType` gt
    then Just $ VDynCast v gt
    else Nothing
castIsValue v (NFFunc ft1) (NFFunc ft2) =
  Just $ VFuncCast v ft1 ft2
castIsValue _ _ _ = Nothing
\end{lstlisting}

If this rule does not apply we check the remaining rules via \texttt{reduceCast'}.

\begin{lstlisting}[caption=Interpreter.hs]
packGType :: NFType -> NFType
packGType = \case
  NFUnit -> NFGType GUnit
  NFLabel ls -> NFGType $ GLabel ls
  NFFunc (FuncType _ _ TDyn TDyn) -> NFGType GFunc
  NFPair (FuncType _ _ TDyn TDyn) -> NFGType GPair
  nfgt@(NFGType _) -> nfgt  -- avoid recursion
  t -> t
\end{lstlisting}
