\chapter{Implementation}\label{chap:implementation}

The actual implementation uses the Haskell programming language and related tools. There are adjustments in all three module groups as classified in section~\ref{sec:program-structure}. Furthermore, we extend the data types in the fundamental \texttt{Syntax} module with additional expressions and types from section~\ref{sec:cc-expressions}, thus making these terms known to the remaining program.

\begin{lstlisting}[caption=Extensions to \texttt{Syntax.hs}]
data Exp = ...
  | Cast Exp Type Type  -- M : A => B

data Type = ...
  | TBot  -- bottom type
  | TDyn  -- dynamic type *
\end{lstlisting}

\section{Parsing}

As usual, there is a tokenization step before the actual parsing, turning a string into tokens. For this purpose, we use the tool \emph{Alex: A lexical analyser generator for Haskell}\footnote{\url{https://www.haskell.org/alex/}}, maintained by Simon Marlow, as it nicely integrates with Haskell. We add tokens for the bottom type and the double arrow used in cast expressions. In our implementation, we use \texttt{*} as identifier for the dynamic type. There already exists a corresponding token since it was used for multiplication in the base language.

\begin{lstlisting}[float,
  caption=Additional tokens (\texttt{Parsing/Tokens.x})]
data Token = ...
  | TBot
  | DoubleArrow

tokens :-
  ...
  Bot    { tok $ const TBot }
  "_|_"  { tok $ const TBot }
  "=>"   { tok $ const DoubleArrow }
\end{lstlisting}

For parsing, we use \emph{Happy: The Parser Generator for Haskell}\footnote{\url{https://www.haskell.org/happy/}}, also maintained by Simon Marlow. Parsing is slightly more complicated since we need to add the dynamic type $\star$, bottom type and the cast expression $M : A \Rightarrow B$.

\begin{lstlisting}[caption=Extensions to \texttt{Parsing/Grammar.y}]
%token
  ...
  Bot   { T _ T.TBot }
  '=>'  { T _ T.DoubleArrow }

Exp = ...
  | Exp ':' Typ '=>' Typ  { Cast $1 $3 $5 }

ATyp = ...
  | '*'  { TDyn }
  | Bot  { TBot }
\end{lstlisting}

\section{Typechecker}

Since terms involving the newly introduced dynamic type are handled at runtime there is no need for extensive changes to the typechecker. Nevertheless, we need to integrate the new syntax. Otherwise, typechecking would fail, not because of type errors but out of ``ignorance''.

\subsection{Type Synthesis}

In general, type synthesis $\Gamma \vdash M \Rightarrow A;\Delta$ takes environment $\Gamma$ and expression $M$ to synthesize its type $A$ and the environment after $\Delta$. We adjust the corresponding function for the following expressions: (1) application, (2) pair construction and for built-in functions (3) \texttt{fst} and (4) \texttt{snd} (both eliminating pairs, yielding the first or second element). In code, it is complemented by a monad transformer, as seen in its annotation, though this is not relevant here.

\begin{lstlisting}[caption=\texttt{tySynth} function type annotation]
tySynth :: TEnv -> Exp -> TCM (Type, TEnv)

type TCM a =
  WriterT [Constraint] (ExceptT String (State Caches)) a

data Caches = Caches{subCache::Cache, eqvCache::Cache}
type Cache = [(Type, Type)]

data Constraint = Type :<: Type
\end{lstlisting}

For application $M~N$, after synthesizing $\Gamma \vdash M \Rightarrow A;\Delta$ and if $A = \star$, we assert that expression $N$ also has dynamic type $\star$.

\begin{lstlisting}[caption=Application type synthesis (\texttt{TCTyping.hs})]
tySynth te (App e1 e2) = do
  (tf, te1) <- tySynth te e1
  tfu <- unfold te1 tf
  case tfu of
    -- ...
    TDyn -> do
      te2 <- tyCheck te1 e2 TDyn
      return (TDyn, te2)
\end{lstlisting}

An expression involving pairs is ``\lstinline[language=ldgv]!let <x, y> = M in N!'', where $M$ has a pair type. First, the components of $M$ are bound to $x$ and $y$, finally evaluating $N$. For typecheckig, we synthesize type $A$ from $M$. Afterwards, we synthesize $\Delta_A, x:\star, y:\star \vdash N \Rightarrow B$ for the whole expression's type.

\begin{lstlisting}[caption=Pair type synthesis (\texttt{TCTyping.hs})]
tySynth te (LetPair x y e1 e2) = do
  (tp, te1) <- tySynth te e1
  tpu <- unfold te1 tp
  case tpu of
    TPair {} -> -- ...
    TDyn -> tySynth
      ((y, (Many, TDyn)) : (x, (Many, TDyn)) : te1)
      e2
\end{lstlisting}

The built-in functions \texttt{fst} and \texttt{snd} simply return the dynamic type $\star$ upon type synthesis since a pair type $\Sigma(x:\star)\star$ implies that both components are of type $\star$, too.

\subsection{Subtyping}

Subtyping regarding the dynamic type happens in the context of \case, used for eliminating label types. For dynamic type $\star$ we need to unfold such \case constructs by recursively checking that each type in its label matching unfolds to $\star$. For this purpose, we extend the existing \texttt{unfold} function as seen in listing~\ref{lst:ccldlc-subtyping-dyn}. If this succeeds, then type checking accepts the outcome, deferring the actual cast to runtime.

\begin{lstlisting}[float,
	caption=Unfolding to $\star$ in case terms (\texttt{TCSubtyping.hs}),
	label=lst:ccldlc-subtyping-dyn]
unfold :: TEnv -> Type -> TCM Type
unfold tenv (TCase val@(Var x) cases) = do
  tyx <- varlookupUnfolding x tenv
  let f :: (String, Type) -> TCM Type
      f (lab, labtyp) = unfold
        (("*unfold*", TEqn val (Lit $ LLab lab) tyx) : tenv)
        labtyp
  results <- case tyx of
    TLab {} -> -- ...
    TDyn -> mapM f cases
  -- if all results are TDyn, return TDyn
\end{lstlisting}

\begin{lstlisting}[float,
	caption=Subtyping for casts in case terms (\texttt{TCSubtyping.hs}),
	label=lst:ccldgv-cast-subtyping]
subtype' tenv
  (TCase (Cast (Var x) t1 (TLab ls2)) cases)
  tyy2 =
    case lookup x tenv of
      Just (_,TLab [l]) -> do
        t <- lablookup l cases
        subtype tenv t tyy2
      _ -> do  -- A-Sub-Case-CL
        let ls' = case t1 of
              TDyn    -> ls2
              TLab ls -> filter (`elem` ls) ls2
              _       -> []
            subtypeCast l = do
              let tenv' = (x,(Many,TLab [l])) : tenv
              cty <- lablookup l cases
              subtype tenv' cty tyy2
        results <- mapM subtypeCast ls'
        return $ foldr1 klub results
\end{lstlisting}

Furthermore, we have to consider casts in context of \case types. Given a type $\case (x : D \Rightarrow L)~\{\overline{\ell : A_\ell}^{\ell \in L}\}$ with variable $x$ and label type $L$ we need to implement subtyping in relation to other types. The following rules describe these relations when checking if \case is a subtype or supertype.

\begin{gather*}
\inferrule[A-Sub-Case-CL]
  {L' = \{ \ell \in L ~|~ \Gamma \Vdash_G \{\ell\} \leq D \}
  	\\
	(\forall \ell \in L') \and
	D_\ell = cast(\{\ell\} \Rightarrow D) \and
	\Gamma, x : D_\ell, \Delta \Vdash A_\ell \leq B
  }
  {\Gamma,x:D,\Delta \Vdash
    \case(x:D \Rightarrow L) \{\overline{\ell : A_\ell}^{\ell \in L}\} \leq B }
\\
\inferrule[A-Sub-Case-CR]
  {L' = \{ \ell \in L ~|~ \Gamma \Vdash_G \{\ell\} \leq D \}
	\\
	(\forall \ell \in L') \and
	D_\ell = cast(\{\ell\} \Rightarrow D) \and
	\Gamma, x : D_\ell, \Delta \Vdash A \leq B_\ell
}
{\Gamma,x:D,\Delta \Vdash
	A \leq \case(x:D \Rightarrow L) \{\overline{\ell : B_\ell}^{\ell \in L}\} }
\\
cast(\{\ell\} \Rightarrow B) =  \begin{cases}
	\{ \ell \} & \text{if } (V:A \Rightarrow B) \Downarrow W \\
	\bot & \text{if } (V:A \Rightarrow B) \Downarrow \blame
\end{cases}
\end{gather*}

When implementing these rules, we assume that type $D$ is either a label type or the dynamic type. This is because in \emph{Gradual LDLC}---as indicated by ``$\Vdash_G$''---there are subtyping rules for these cases. For label type $L$ we can establish subtyping if $L \subseteq D$ and for dynamic type $D=\star$ every type $A$ is a subtype of $D$. Function \emph{cast} checks if a type cast is possible, returning a singleton type on success. Since a successful subtyping check for $\{\ell\} \leq D$ already indicates a successful cast $\{\ell \Rightarrow D\}$ we did omit an explicit implementation of the \emph{cast} function.

Furthermore, we implement additional logic regarding these rules: If typing environment $\Gamma$ already contains a binding to a singleton label $x : \{\ell\}$ this is utilized for resolving the \case type, directly checking subtyping $A_\ell \leq B$ or $A \leq B_\ell$ respectively. Otherwise, variable $x$ would serve no purpose. Deliberately ignoring its binding would render aforementioned logic redundant, hence the \case type would not be resolved. The corresponding code for \textsc{A-Sub-Case-CL} is given in listing~\ref{lst:ccldgv-cast-subtyping}. Rule \textsc{A-Sub-Case-CL} is nearly identical.

\section{Interpreter}

In basic LDGV, types are not relevant in context of evaluation. The interpreter works on the assumption that prior type checking did succeed. In our extension, cast expressions are always handled at runtime, even if both types in a cast $M : A \Rightarrow B$ are not dynamic ($A \neq \star, B \neq \star$).
For correct handling of the dynamic type and type reduction of cast expressions we introduce new data types and extend the existing data type for values. Finally, we implement the rules of section~\ref{sec:ccldlc-inference-rules}.

In chapter~\ref{chap:cast-calculus} we also listed rules for handling singleton types $\Single\{A\}$ as given in the original paper. The implementation does not support explicit singleton types in its grammar. Therefore, from this point onwards, singleton types will not be considered.

\subsection{Type Passing}

Since type reduction requires \emph{head normal form} we introduce an explicit data type \texttt{NFType} in listing~\ref{lst:hnf-typedef}. Label type $L$ is implemented as a set of strings. Similarities between function type $(\rho, \Pi(x:A)B)$ and pair type $(\rho, \Sigma(x:A)B)$ are  depicted using the \texttt{FuncType} data type.

\begin{lstlisting}[float,
  label=lst:hnf-typedef,
  caption=HNF type definition (\texttt{ProcessEnvironment.hs})]
data NFType
  = NFBot
  | NFDyn
  | NFFunc FuncType
  | NFPair FuncType
  | NFGType GType

data FuncType = FuncType PEnv String Type Type
\end{lstlisting}

The constructor \texttt{NFGType} is a special case. It takes an argument of type \texttt{GType}---the data type implementing \emph{ground types}---which we define in listing~\ref{lst:gtype}. This type dependency depicts that every ground type is also in head normal form---but not the other way around---while making comparison operations between \texttt{NFType} and \texttt{GType} possible. At the same time, defining ground types as a separate data type allows for more precise function signatures. Even so, we can not perfectly model the relationship since Haskell itself is not dependently typed. A function type $(\cdot, \Pi(x:\star)\star)$ can be written as \texttt{NFGType GFunc} or as \texttt{NFFunc (FuncType [] "x" TDyn TDyn)}. The latter is semantically correct but must not occur it most contexts. We have to resort to helper function like \texttt{equalsType} and additional logic to resolve such cases.

\begin{lstlisting}[float,
  caption=Ground type definition (\texttt{ProcessEnvironment.hs}),
  label=lst:gtype]
data GType
  = GUnit
  | GLabel LabelType
  | GFunc String
  | GPair String
  | GNat
  | GInt
  | GDouble
  | GString

type Label = String
type LabelType = Set Label

equalsType :: NFType -> GType -> Bool
equalsType (NFFunc (FuncType _ _ s TDyn TDyn)) (GFunc s') =
  s == s'
equalsType (NFPair (FuncType _ _ s TDyn TDyn)) (GPair s') =
  s == s'
equalsType (NFGType gt1) gt2 = gt1 == gt2
equalsType _ _ = False
\end{lstlisting}

Subtyping checks are implemented in listing~\ref{lst:subtypeable} instroducing typeclass \texttt{Subtypeable} with instances for ground types \texttt{GType}---mostly with trivial definitions---and partially for HNF types \texttt{NFType}. The latter is solely necessary for implementing the \textsc{Cast-Dyn-Dyn} rule.

\begin{lstlisting}[float,
  label=lst:subtypeable,
  caption=Subtypeable typeclass (\texttt{ProcessEnvironment.hs})]
class Subtypeable t where
  isSubtypeOf :: t -> t -> Bool

instance Subtypeable GType where
  isSubtypeOf GUnit GUnit = True
  isSubtypeOf (GLabel ls1) (GLabel ls2) =
    ls1 `Set.isSubsetOf` ls2
  isSubtypeOf (GFunc _) (GFunc _) = True
  isSubtypeOf (GPair _) (GPair _) = True
  isSubtypeOf GNat GNat = True
  isSubtypeOf GInt GInt = True
  isSubtypeOf GDouble GDouble = True
  isSubtypeOf GString GString = True
  isSubtypeOf _ _ = False

instance Subtypeable NFType where
  isSubtypeOf NFBot _ = True
  isSubtypeOf NFDyn NFDyn = True
  -- ...
  isSubtypeOf _ _ = False
\end{lstlisting}

We also extend the value type according to section~\ref{sec:cc-expressions}. We add function closures, including environment $\rho$, variable name and the expression in the function's body. Furthermore function casts and the dynamic wrapper $(V : G \Rightarrow \star)$ (see listing~\ref{lst:ccldlc-value-type}).

\begin{lstlisting}[float,
  label=lst:ccldlc-value-type,
  caption=Value type extensions (\texttt{ProcessEnvironment.hs})]
data Value = -- ...
  | VFunc PEnv String Exp
  | VFuncCast Value FuncType FuncType
  | VDynCast Value GType
\end{lstlisting}

We use these new and extended data types to handle CCLDLC's types during the interpretation state, especially for type inference in cast expressions. At last, we need a mapping to HNF types used in type casts. We introduce the \texttt{evalType} function in listing~\ref{lst:type-eval} to evaluate types to their HNF form. Mostly, this evaluation is trivial. For function and pair types, the environment is made part of the type. Most involved is evaluation of the $\case x~\{\ell_i : A_i\}$ type since case types are never in HNF. We match label $x \downarrow \ell_j$ on the type mapping, finally evaluating $A_j \downarrow A^\circ$. If possible, we evaluate to ground types and wrap them using the \texttt{NFGType} constructor.

\begin{lstlisting}[float,
  caption=Type evaluation (\texttt{Interpreter.hs}),
  label=lst:type-eval]
evalType :: Type -> InterpretM NFType
evalType = \case
  TUnit   -> return $ NFGType GUnit
  TNat    -> return $ NFGType GNat
  TInt    -> return $ NFGType GInt
  TDouble -> return $ NFGType GDouble
  TString -> return $ NFGType GString
  TBot    -> return NFBot
  TDyn    -> return NFDyn
  TLab ls -> return $ NFGType $ GLabel ls
  TFun  _ _ TDyn TDyn -> return $ NFGType GFunc
  TFun  _ s t1 t2 -> do
    env <- ask
    return $ NFFunc $ FuncType env s t1 t2
  TPair _ _ TDyn TDyn -> return $ NFGType GPair
  TPair _ s t1 t2 -> do
    env <- ask
    return $ NFPair $ FuncType env s t1 t2
  TCase exp labels -> interpret' exp >>= \(VLabel l) ->
    let entry = find (\(l', _) -> l == l') labels
    in maybe (return NFBot) (evalType . snd) entry
\end{lstlisting}

\subsection{Cast Reduction}

The goal of type inference at runtime is to either reduce casts in a way that evaluation halts at a value, or to abort evaluation with \blame. In our implementation, the latter throws an exception. During this section we describe the implementation of the rules stated in figure~\ref{fig:ccldlc-extensions-values}.

We extended the language with cast expression $M : A \Rightarrow B$. However, a cast reduction has to have form $V : A^\circ \Rightarrow B^\circ$. Hence, we use rule \textsc{Cast-Reduce} to evaluate expression $M$ to value $V$ and types $A$ and $B$ to HNF $A^\circ$ and $B^\circ$ respectively. For that purpose, we extend the existing \texttt{eval} function according to listing~\ref{lst:cast-reduce}. This function implements the interpreter's main logic, mapping all the language's expressions (see figure~\ref{fig:ldlc-expressions}) to values. The \texttt{InterpretM} monad from the function's signature represents evaluation environment $\rho$, providing the \emph{Reader} monad's interface.\footnote{\url{https://hackage.haskell.org/package/transformers-0.6.0.4/docs/Control-Monad-Trans-Reader.html}}

\begin{lstlisting}[float,
  caption=Cast expression evaluation (\texttt{Interpreter.hs}),
  label=lst:cast-reduce]
eval :: Exp -> InterpretM Value
eval cast@(Cast e t1 t2) = do
  v <- interpret' e
  nft1 <- evalType t1
  nft2 <- evalType t2
  maybe (blame cast) return (reduceCast v nft1 nft2)
\end{lstlisting}

Cast reduction $V : A^\circ \Rightarrow B^\circ \Downarrow V'$ is implemented in the \texttt{reduceCast} function. Its type signature matches the term as it requires a value and two types in HNF. However, upon failure it will not return \blame directly but encapsulates its result into a \texttt{Maybe} type. Then, the calling function needs to call \blame upon an empty result (e.g. see listing~\ref{lst:cast-reduce}).

The basic \textsc{Cast-Is-Value} rule returns $V : A^\circ \Rightarrow B^\circ$ as it is if it already forms a value. This occurs for $A^\circ = G, B^\circ = \star$ (\texttt{VDynCast}) or for function casts, i.e. $A^\circ=(\rho, \Pi(x:A)A'), B^\circ=(\rho, \Pi(x:B)B')$ (\texttt{VFuncCast}). When implementing the latter we have to consider the ground type \texttt{GFunc} that is also a valid function type but is on a different level in the type hierarchy. Therefore, more code is necessary to handle conversion. If the \textsc{Cast-Is-Value} rule does not apply we check the remaining rules via distinct function \texttt{reduceCast'} as \emph{alternative} (indicated by the \texttt{<|>} operator). The code is given in listing~\ref{lst:cast-is-value}.

\begin{lstlisting}[float,
  caption=Rule \textsc{Cast-Is-Value} (\texttt{Interpreter.hs}),
  label=lst:cast-is-value]
reduceCast :: Value -> NFType -> NFType -> Maybe Value
reduceCast v t1 t2 = castIsValue v t1 t2
                 <|> reduceCast' v t1 t2

castIsValue :: Value -> NFType -> NFType -> Maybe Value
castIsValue v (NFGType gt) NFDyn = Just $ VDynCast v gt
castIsValue v (NFFunc ft1) (NFFunc ft2) =
  Just $ VFuncCast v ft1 ft2
castIsValue v (NFFunc ft1) (NFGType (GFunc y)) =
  Just $ VFuncCast v
    ft1 (FuncType [] y TDyn TDyn)
castIsValue v (NFGType (GFunc x)) (NFFunc ft2) =
  Just $ VFuncCast v
    (FuncType [] x TDyn TDyn) ft2
castIsValue v (NFGType (GFunc x)) (NFGType (GFunc y)) =
  Just $ VFuncCast v
    (FuncType [] x TDyn TDyn) (FuncType [] y TDyn TDyn)
castIsValue _ _ _ = Nothing
\end{lstlisting}

For some rules we match HNF types to ground types as defined in figure~\ref{fig:ccldlc-type-matching}. The actual code of listing~\ref{lst:type-matching} is more concise that the definition because of the way we encapsulated \texttt{GType} and since we do not consider singleton types.

\begin{lstlisting}[float,
  caption=Type matching $A^\circ \rhd G$ (\texttt{Interpreter.hs}),
  label=lst:type-matching]
matchType :: NFType -> Maybe GType
matchType = \case
  NFFunc (FuncType _ _ x _ _) -> Just $ GFunc x
  NFPair (FuncType _ _ x _ _) -> Just $ GPair x
  NFGType gt -> Just gt
  _ -> Nothing
\end{lstlisting}

The remaining rules necessary for a full implementation of CCLDLC , except these for function and pair handling, are handled by the \texttt{reduceCast'} function we describe in the next paragraphs.

Rules \textsc{Cast-Dyn-Dyn} and \textsc{Factor-Left} are similar such that they presume a cast \emph{to} dynamic type $\star$. Hence, we implement them together as in listing~\ref{lst:cast-dyn-dyn-factor-left}. Currently, the only subtypes of $\star$ are $\star$ itself and bottom type $\bot$ which is expressed using typeclass \texttt{Subtypeable} (listing~\ref{lst:subtypeable}). If the given type is no subtype of $\star$ we apply \textsc{Factor-Left} as is. After type matching $A^\circ \rhd G$ we do not implement the check that $A^\circ \neq G$. Given the function's arguments this would imply a cast $V : G \Rightarrow \star$ that would have been handled by an earlier call to \texttt{castIsValue}.

\begin{lstlisting}[float,
  label=lst:cast-dyn-dyn-factor-left,
  caption=Rules \textsc{Cast-Dyn-Dyn} and \textsc{Factor-Left} (\texttt{Interpreter.hs})]
reduceCast' v t NFDyn =
  if t `isSubtypeOf` NFDyn
  then Just v --Cast-Dyn-Dyn
  else do
    gt <- matchType t
    v' <- reduceCast v t (NFGType gt)
    Just $ VDynCast v' gt
\end{lstlisting}

There is no type that is a subtype of the bottom type $\bot$. Hence, a cast to $\bot$ must always results in blame which is expressed in rule \textsc{Cast-Bot}.

\begin{lstlisting}[caption=Rule \textsc{Cast-Bot} (\texttt{Interpreter.hs})]
reduceCast' _ _ NFBot = Nothing
\end{lstlisting}

It is straightforward to implement rules \textsc{Cast-Collapse} and \textsc{Cast-Collide}. Even though dynamic type $\star$ does not support transitivity w.r.t. subtyping, these rules enable transitivity for ground types only. The code is given in listing~\ref{lst:cast-collapse}.

\begin{lstlisting}[float,
  caption=Rules \textsc{Cast-Collapse} and \textsc{Cast-Collide} (\texttt{Interpreter.hs}),
  label=lst:cast-collapse]
reduceCast' (VDynCast v gt1) NFDyn (NFGType gt2) =
  if gt1 `isSubtypeOf` gt2 then Just v else Nothing
\end{lstlisting}

Rule \textsc{Factor-Right} describes a cast from $\star$ to another type (listing~\ref{lst:factor-right}). Its utilization of \emph{type matching} $\rhd$ makes it similar to \textsc{Factor-Left}. A failure results in \blame since rules with similar structure, namely \textsc{Cast-Collapse} and \textsc{Cast-Collide}, were handled before by pattern matching over more specific arguments.

\begin{lstlisting}[float,
  caption=Rule \textsc{Factor-Right} (\texttt{Interpreter.hs}),
  label=lst:factor-right]
reduceCast' v NFDyn t = do
  gt <- matchType t
  let nfgt = NFGType gt
  if not (t `equalsType` gt) then do
    v'  <- reduceCast v NFDyn nfgt
    v'' <- reduceCast v' nfgt t
    Just v''
  else
    Nothing
\end{lstlisting}

Finally, we give a simple implementation for rule \textsc{Cast-Sub} which simply checks subtyping between given ground types. On failure, this simply returns \blame without any additional checks. Also, we completely omit rule \textsc{Cast-Fail}. This is because it is the last rule in context of \texttt{reduceCast'}. There are no cases left to examine so any cast not yet covered must fail.

\begin{lstlisting}[caption=Rule \textsc{Cast-Sub} (\texttt{Interpreter.hs})]
reduceCast' v (NFGType gt1) (NFGType gt2) =
  if gt1 `isSubtypeOf` gt2 then Just v else Nothing
\end{lstlisting}

The last two are about type reductions in context of pairs and functions. First, we implemnt \textsc{Cast-Pair}. For this purpose we make adjustments to the \texttt{eval} function in listing~\ref{lst:cast-reduce} which returns monad \texttt{InterpretM}. This is necessary since we need to consider the expression's environment $\rho$. The type annotation of function \texttt{reduceCast} does not accept arguments capable of representing the environment. After evaluating to $V : A^\circ \Rightarrow B^\circ$ we catch pair values by pattern matching and pass the cast term to function \texttt{reducePairCast} as seen in listing~\ref{lst:pair-cast}. Again, we need a helper function to manage overlapping types. With \texttt{toNFPair} we intercept ground types, using type constructor \texttt{NFPair} instead of \texttt{NFGType}. This is necessary since \texttt{reducePairCast} only matches the former. Alternatively, one might match against all combinations of both type constructors as in function \texttt{castIsValue} from listing~\ref{lst:cast-is-value}. The actual cast reduction consists of simply reducing both of its components. When reducing the second component, we extend the respective environments with the first components' values (\texttt{xEnv}).

\begin{lstlisting}[float,
  caption=Rule \textsc{Cast-Pair} (\texttt{Interpreter.hs}),
  label=lst:pair-cast]
eval cast@(Cast e t1 t2) = do
  v    <- interpret' e
  nft1 <- evalType t1
  nft2 <- evalType t2
  case v of
    -- catch pair values
    VPair {} -> do
      v' <- lift $ reducePairCast
        v (toNFPair nft1) (toNFPair nft2)
      maybe (blame cast) return v'
    -- as before
    _ -> maybe (blame cast) return (reduceCast v nft1 nft2)

toNFPair (NFGType (GPair s)) =
  NFPair (FuncType [] [] s TDyn TDyn)
toNFPair t = t

reducePairCast
  (VPair v w)
  (NFPair (FuncType env  s  t1  t2))
  (NFPair (FuncType env' s' t1' t2')) = do
    mv' <- reduceComponent v (env, t1) (env', t1')
    case mv' of
      Nothing -> return Nothing -- first reduce failed
      Just v' -> do
        let xEnv  = (s,  v)  : env
            xEnv' = (s', v') : env'
        mw' <- reduceComponent w (xEnv, t2) (xEnv', t2')
        return $ liftM2 VPair mv' mw'

reduceComponent v (env, t) (env', t') = do
  nft  <- R.runReaderT (evalType t)  env,
  nft' <- R.runReaderT (evalType t') env'
  return $ reduceCast v nft nft'
\end{lstlisting}

Finally, we implement \textsc{Cast-Function} by---again---extending function \texttt{eval} for application $M~N$. Formerly, this separately did evaluate expressions $M \downarrow V$ and $N \downarrow W$ to values. Given $V$ is a function $(\rho, \lambda x. M')$ it extends environment $\rho$ with $x=W$, then evaluating $M'$ in its context. Otherwise, it would fail. For our extension we introduce function \texttt{interpretApp} taking values $V$ as $W$ as arguments in listing~\ref{lst:cast-function}. This allows for more involved functionality by matching over its arguments' types. Apart from that, the code mostly reflects the rule, using \texttt{runReaderT} from the \emph{Reader} monad to respectively pass the correct environment.

\begin{lstlisting}[float,
  caption=Rule \textsc{Cast-Function} (\texttt{Interpreter.hs}),
  label=lst:cast-function]
interpretApp :: Value -> Value -> InterpretM Value
interpretApp (VFuncCast v
  (FuncType env  s  t1  t2)
  (FuncType env' s' t1' t2')) w' = do
    env0 <- ask
    let interpretAppCast = do
      nft1  <- R.runReaderT (evalType t1)  env
      nft1' <- R.runReaderT (evalType t1') env'
      w  <- maybe blame return (reduceCast w' nft1' nft1)
      nft2' <- R.runReaderT (evalType t2') ((s', w') : env)
      nft2  <- R.runReaderT (evalType t2)  ((s,  w)  : env)
      u  <-    R.runReaderT (interpretApp v w) env0
      u' <- maybe blame return (reduceCast u nft2 nft2')
      return u'
    lift interpretAppCast
\end{lstlisting}

\section{Function Cast Example}

To give an intuition about the reduction of cast expressions regarding the rules and implementation we show a non-trivial example. We evaluate a nested lambda expression taking two arguments $x,y$. While $x$ hat type \Bool, the type of $y$ is dynamic. In the function's body $y$ depends on the value of $x$, hence a cast. If $x=\ell_F$ then $y$ is a function mapping one boolean argument to a boolean result, then applying $x$. Else, for $x=\ell_T$, $y$ is a function expecting \emph{two} arguments, applying $x$ two successive times. Please note that the actual code in listing~\ref{lst:ccldgv-example1} is nearly identical to CCLDLC form in equation~\ref{eqn:ccldlc-example1}.

\begin{equation}\label{eqn:ccldlc-example1}
\begin{split}
f = & \lambda (x: \Bool)
. \lambda (y: \star )
. \case x \{ \\
& \qquad \ell_F: (y : \star \Rightarrow (a:\Bool) \rightarrow \Bool)~x, \\
& \qquad \ell_T: (x : \star \Rightarrow (a:\Bool) \rightarrow (b:\Bool) \rightarrow \Bool)~x~x \} \\
: & \Pi(x : \Bool) . \Pi (y: \star ) . \Bool
\end{split}
\end{equation}

\begin{lstlisting}[language=ldgv,
  label=lst:ccldgv-example1,
  caption=CCLDGV example ``dependent function cast'']
val f = fn(x: Bool) fn(y: *) case x {
          'F: (y: * => (a:Bool) -> Bool) x,
          'T: (y: * => (a:Bool) -> (b:Bool) -> Bool) x x}
\end{lstlisting}

By applying label $\ell_F$ (representing boolean \emph{False}) and boolean function $\notf = \lambda (x:\Bool) \case x \{ \ell_T: \ell_F, \ell_F: \ell_T\}$ we evaluate the whole expression to value $\ell_T$. This is presented in a step-by-step manner, starting with an application and an explicit dynamic cast of function not. For brevity, we omit the environment $\rho$ inside equations.

\begin{align}
& f~\ell_F~~(\notf : (a:\Bool) \rightarrow \Bool \Rightarrow \star) \\
( & f~\ell_F)~(\notf : (a:\Bool) \rightarrow \Bool \Rightarrow \star)
\end{align}

First, we evaluate the left part of the application, which is an application itself: $f~\ell_F$. This part does not involve the \emph{Cast Calculus}, simply binding $x=\ell_F$ in the function's environment $\rho$, returning $f' := \lambda (y:\star) \case x \{ \dots \}$. Next, we evaluate the right side's cast expression using rule \textsc{Factor-Left} (\ref{eqn:ex1-factor-left}) which enfolds \textsc{Cast-Is-Value} (\ref{eqn:ex1-cast-is-value}). This results in a value $v' := (V : G \Rightarrow \star)$ where $V$ is a function cast and $G$ is \underline{function ground type} $\Pi(a:\star)\star$.

\begin{align}
& \Pi(a:\Bool) \Bool \rhd \underline{\Pi(a:\star) \star} \\ \hline
& \notf : \Pi(a:\Bool) \Bool \Rightarrow \underline{\Pi(a:\star) \star} \\
\Downarrow ( & \notf : \Pi(a:\Bool) \Bool \Rightarrow \Pi(a:\star) \star ) \label{eqn:ex1-cast-is-value} \\ \hline
& \notf : \Pi(a:\Bool) \Bool \Rightarrow \star \\
\Downarrow (( & \notf : \Pi(a:\Bool) \Bool \Rightarrow \Pi(a:\star) \star) : \underline{\Pi(a:\star) \star} \Rightarrow \star) \label{eqn:ex1-factor-left} \\
= (& ~V \hspace{16.6em} : G \hspace{3.1em} \Rightarrow \star) =: v'
\end{align}

Now, we evaluate new-formed expression $f'~v'$, again an application. Evaluating the body of $f'$, the \case term matches to label $\ell_F$. Substituting $f'[v'/y]$ results in cast expression $(v' : \star \Rightarrow \Pi(a:\Bool) \Bool)$. Since the right part of the cast is not a ground type we need to apply \textsc{Factor-Right} (\ref{eqn:ex1-factor-right}), including \textsc{Cast-Collapse} (\ref{eqn:ex1-cast-collapse}) and \textsc{Cast-Is-Value} (\ref{eqn:ex1-cast-is-value2}) for intermediate values. Invoking this cast reduction results in a function cast value $v'' := (V : \Pi(a: \star) \star \Rightarrow \Pi(a:\Bool) \Bool)$ with $V$ being a function cast, too (the same as above).

\begin{align}
\Pi(a:\Bool) \Bool & \rhd \underline{\Pi(a:\star)\star} \\ \hline
v' : \star & \Rightarrow \underline{\Pi(a:\star)\star} \\
= ( V : \underline{\Pi(a:\star) \star} \Rightarrow \star) : \star & \Rightarrow \underline{\Pi(a:\star) \star}
\Downarrow V \label{eqn:ex1-cast-collapse} \\ \hline
V : \underline{\Pi(a:\star) \star} & \Rightarrow \Pi(a:\Bool) \Bool \\
\Downarrow (V : \Pi(a:\star) \star & \Rightarrow \Pi(a:\Bool) \Bool) \label{eqn:ex1-cast-is-value2} \\ \hline
v' : \star & \Rightarrow \Pi(a:\Bool) \Bool \\
\Downarrow (V : \Pi(a:\star) \star & \Rightarrow \Pi(a:\Bool) \Bool) =: v'' \label{eqn:ex1-factor-right}
\end{align}

Finally, we evaluate the full expression in the example function's false branch. We substitue the cast of variable $y$ with $v''$ and variable $x$ with $\ell_F$. What remains is application $v''~\ell_F$. Since $v''$ is a function cast value we use rule \textsc{Cast-Function} (\ref{eqn:cast-function}). This includes reduction of application $V~(\ell_F : \Bool \Rightarrow \star)$ which we need to solve first, using \textsc{Cast-Function}, too (\ref{eqn:cast-function-nested}), as well as \textsc{Cast-Collapse} (\ref{eqn:ex1-cast-collapse2}) (\ref{eqn:ex1-cast-collapse3}).

\begin{align}
(&\ell_F : \Bool \Rightarrow \star) : \star \Rightarrow \Bool \Downarrow \ell_F \label{eqn:ex1-cast-collapse2} \\ \hline
&~V~ \hspace{16.6em} (\ell_F : \Bool \Rightarrow \star) \\
= ( &\notf : \Pi(a:\Bool) \Bool \Rightarrow \Pi(a:\star) \star)~(\ell_F : \Bool \Rightarrow \star) \\
\Downarrow ( &\notf \ell_F ) : \Bool \Rightarrow \star \\
\downarrow ~~&~\ell_T : \Bool \Rightarrow \star \label{eqn:cast-function-nested} \\
\Downarrow (&~\ell_T : \Bool \Rightarrow \star) \\ \hline
( & ~V~(\ell_F : \Bool \Rightarrow \star)) : \star \Rightarrow \Bool \\
\downarrow (&~\ell_T : \Bool \Rightarrow \star) : \star \Rightarrow \Bool \label{eqn:cast-function} \\
\Downarrow ~~ & ~\ell_T \label{eqn:ex1-cast-collapse3}
\end{align}

In conclusion, even the reductions for a relatively simple function cast are quite involved, requiring many rules and operations. Note that when full \emph{gradual typing} is implemented, the explicit casts are not written out by the programmer.

\section{Recursor Expression}

The \emph{Cast Calculus} revolves around type casts and the dynamic type. Until now, we did provide an exhaustive description of these newly introduced constructs, its rules and an implementation. In the same breath we will extend the natural recursor and prepare its integration into the \emph{Cast Calculus}.

The current implementation of $\rec V~M~x.f.N$ is mostly as its description in section~\ref{sec:ldgv-recursor}. Its syntax is \texttt{rec f (x.es) ez} with variable names \texttt{f,z} and expressions \texttt{es,ez}. For recursively evaluating the expression a natural number is necessary. This is implemented by application. When applying a number \texttt{n} to a correct \rec expression $r$ evaluation yields a value: \texttt{r n} implements $\rec V~M~x.f.N$ for $V=n$.

\begin{lstlisting}[float,
	label=lst:rec-typeext,
	caption=(\texttt{ProcessEnvironment.hs})]
data Value = -- ...
    | VRec PEnv String String Exp Exp
\end{lstlisting}

\begin{lstlisting}[float,
	label=lst:rec-eval,
	caption=(\texttt{Interpreter.hs})]
eval Rec f x es ez = ask >>= \env ->
  return $ VRec env f x es ez
  
interpretApp rec@(VRec env f x es ez) (VInt n)
  | n == 0 = interpret' ez
  | n  > 0 = do
    let env' = extendEnv x (VInt (n-1))
              (extendEnv f rec env)
    R.local (const env') (interpret' es)
\end{lstlisting}

Additionally, we prepare evaluation of type $\rec V~A~t.B$ to \emph{head normal form}. Parsing term \texttt{natrec e \{ tz, tid.ts \}} maps to a corresponding type representation \texttt{TNatRec} as defined in \texttt{Syntax.hs}. Whereas \texttt{e} is an expression, it has to evaluate to a number value. Next, evaluation proceeds similar to its expression counterpart seen above with base type \texttt{tz} and recursive evaluation for \texttt{es}. The code is given in listing~\ref{lst:rec-typeeval}.

In listing~\ref{lst:rec-ldgv-example} we give examples for the usage of \rec in  LDGV. The first example, \texttt{notrec}, constructs successive applications of the not function, starting with value \texttt{'F} (representing False). The second example \texttt{sumrec} constructs a function taking $n+1$ integer arguments, returning their sum. Both functions have in common that they expect a natural number for their first argument. This is sufficient to recursively evaluate the type using the \texttt{natrec} construct.

\begin{lstlisting}[float,
	label=lst:rec-typeeval,
	caption=Evaluation of \rec type to HNF(\texttt{Interpreter.hs})]
evalType TNatRec e tz tid ts = do
  v <- interpret' e
  case v of
    VInt 0 -> evalType tz
    VInt n ->
      let lower = TNatRec (Lit $ LNat (n-1)) tz tid ts
      in R.local (extendEnv tid (VType lower)) (evalType ts)
\end{lstlisting}

\begin{lstlisting}[float, language=ldgv,
	caption=Example usage of \rec expression and type,
	label=lst:rec-ldgv-example]
val notrec : (n: Nat) -> natrec n {Bool, A.A}
val notrec = rec f (x.nof(f x)) 'F

val sumrec : (n: Nat) -> natrec n {Int, A.Int -> A}
val sumrec = rec f
  (n1 . (fn (acc : Int) fn (x : Int) f n1 (acc + x)))
  (fn (acc: Int) acc)
\end{lstlisting}

Currently, recursor expressions and types do not fully integrate into the \emph{Cast Calculus}. Casting from and to recursor types remains complicated to write out. Furthermore, type evaluation does require knowledge of number value $n$ which must be available at runtime. For more precise typing, introducing an additional type for restricted natural numbers $n \leq x$ would prove advantageous, too. In conclusion, while casts and elimination (via \textbf{case}) of labels provide elegant functionality, their number-dependent counterpart---\textbf{rec} types and expressions---still needs some work.